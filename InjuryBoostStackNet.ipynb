{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8d9795-4e9e-479d-ad60-aa0e1d235ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, matthews_corrcoef, cohen_kappa_score, confusion_matrix\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define the InjuryBoostStackNet class\n",
    "class InjuryBoostStackNet:\n",
    "    def __init__(self):\n",
    "        # Initialize encoders and scaler\n",
    "        self.encoders = {}\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "        # Base models\n",
    "        self.rf = RandomForestClassifier(n_estimators=100, max_depth=15, random_state=42)\n",
    "        self.lgb = lgb.LGBMClassifier(n_estimators=150, num_leaves=31, learning_rate=0.05, random_state=42)\n",
    "        self.mlp = MLPClassifier(hidden_layer_sizes=(64, 32), activation='relu', solver='adam',\n",
    "                                 alpha=0.0001, max_iter=500, random_state=21)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de7253d-3929-48e3-a955-c5aa03fa2b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def preprocess(self, df):\n",
    "        # Drop irrelevant ID columns\n",
    "        df = df.drop(columns=[\"Player Name\", \"Team Name\"], errors='ignore')\n",
    "\n",
    "        # Label encode categorical features\n",
    "        for col in ['Position', 'Injury Type']:\n",
    "            if col in df.columns:\n",
    "                self.encoders[col] = LabelEncoder()\n",
    "                df[col] = self.encoders[col].fit_transform(df[col].astype(str))\n",
    "\n",
    "        # Separate features and target\n",
    "        if \"Performance Drop Binary\" not in df.columns:\n",
    "            raise ValueError(\"Target column 'Performance Drop Binary' not found.\")\n",
    "\n",
    "        features = df.drop(columns=[\"Performance Drop\", \"Performance Drop Binary\"], errors='ignore')\n",
    "        target = df[\"Performance Drop Binary\"]\n",
    "\n",
    "        # Normalize features\n",
    "        features_scaled = pd.DataFrame(self.scaler.fit_transform(features), columns=features.columns)\n",
    "\n",
    "        return features_scaled, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f8f10a-487b-439f-a8fb-bafa4b90a439",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def train_and_evaluate(self, X, y):\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        results = {\n",
    "            'accuracy': [], 'precision': [], 'recall': [], 'f1': [],\n",
    "            'roc_auc': [], 'specificity': [], 'mcc': [], 'kappa': []\n",
    "        }\n",
    "\n",
    "        for fold_idx, (train_idx, test_idx) in enumerate(skf.split(X, y), 1):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "            # Train base models\n",
    "            rf_pred = self.rf.fit(X_train, y_train).predict_proba(X_test)[:, 1]\n",
    "            lgb_pred = self.lgb.fit(X_train, y_train).predict_proba(X_test)[:, 1]\n",
    "            mlp_pred = self.mlp.fit(X_train, y_train).predict_proba(X_test)[:, 1]\n",
    "\n",
    "            # Average ensemble\n",
    "            final_pred = (rf_pred + lgb_pred + mlp_pred) / 3\n",
    "            final_class = (final_pred >= 0.5).astype(int)\n",
    "\n",
    "            # Confusion matrix for specificity\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test, final_class).ravel()\n",
    "\n",
    "            # Collect metrics\n",
    "            results['accuracy'].append(accuracy_score(y_test, final_class))\n",
    "            results['precision'].append(precision_score(y_test, final_class))\n",
    "            results['recall'].append(recall_score(y_test, final_class))\n",
    "            results['f1'].append(f1_score(y_test, final_class))\n",
    "            results['roc_auc'].append(roc_auc_score(y_test, final_pred))\n",
    "            results['specificity'].append(tn / (tn + fp))\n",
    "            results['mcc'].append(matthews_corrcoef(y_test, final_class))\n",
    "            results['kappa'].append(cohen_kappa_score(y_test, final_class))\n",
    "\n",
    "            # ðŸ‘‰ Visualize only for the final (5th) fold\n",
    "            if fold_idx == 5:\n",
    "                print(f\"\\nðŸ“Š Visualizations for Fold {fold_idx}:\")\n",
    "                plot_confusion_matrix(y_test, final_class)\n",
    "                plot_roc_curve(y_test, final_pred)\n",
    "                plot_f1_threshold(y_test, final_pred)\n",
    "\n",
    "        # Return mean metrics\n",
    "        return {k: np.mean(v) for k, v in results.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968e32b9-a175-4533-895b-fa4119e466b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your dataset\n",
    "\n",
    "    # Initialize model\n",
    "    model = InjuryBoostStackNet()\n",
    "\n",
    "    # Preprocess data\n",
    "    X, y = model.preprocess(df)\n",
    "\n",
    "    # Train and evaluate\n",
    "    results = model.train_and_evaluate(X, y)\n",
    "\n",
    "    # Print evaluation results\n",
    "    print(\"Cross-Validation Results:\")\n",
    "    for metric, value in results.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25231aba-ae68-49f4-8a49-018fb628da50",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def explain_shap(self, X, max_display=10):\n",
    "        \"\"\"\n",
    "        Generate SHAP explanations using LightGBM.\n",
    "        :param X: Scaled feature DataFrame\n",
    "        :param max_display: Number of top features to show\n",
    "        \"\"\"\n",
    "        # Use TreeExplainer on trained LightGBM model\n",
    "        explainer = shap.TreeExplainer(self.lgb)\n",
    "        shap_values = explainer.shap_values(X)\n",
    "\n",
    "        # Summary plot for feature importance (bar)\n",
    "        print(\"SHAP Feature Importance:\")\n",
    "        shap.summary_plot(shap_values, X, plot_type=\"bar\", max_display=max_display)\n",
    "\n",
    "        # Summary plot for feature effect (beeswarm)\n",
    "        shap.summary_plot(shap_values, X, max_display=max_display)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314eb420-05e8-4ea0-927c-da9e5a70211a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After model training:\n",
    "model.explain_shap(X)  # Where X is your preprocessed feature matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76a77b0-1759-49c0-b725-6a214c2b9a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, f1_score\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title=\"Confusion Matrix\"):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "                xticklabels=[\"No Drop\", \"Drop\"], yticklabels=[\"No Drop\", \"Drop\"])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_curve(y_true, y_score):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f\"ROC curve (AUC = {roc_auc_score(y_true, y_score):.2f})\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_f1_threshold(y_true, y_score):\n",
    "    thresholds = np.linspace(0.0, 1.0, 100)\n",
    "    f1_scores = [f1_score(y_true, (y_score >= t).astype(int)) for t in thresholds]\n",
    "    plt.figure()\n",
    "    plt.plot(thresholds, f1_scores, label=\"F1 Score\")\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "    plt.title(\"F1 Score vs. Threshold\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f0ed67-8947-4353-9630-0bd8fe7d0da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "def track_training_time_and_memory(model, X, y):\n",
    "    def _train():\n",
    "        model.train_and_evaluate(X, y)\n",
    "\n",
    "    start_time = time.time()\n",
    "    mem_usage = memory_usage(( _train, ), interval=0.1)\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Total Training Time: {end_time - start_time:.2f} seconds\")\n",
    "    print(f\"Peak Memory Usage: {max(mem_usage):.2f} MB\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
